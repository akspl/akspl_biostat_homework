---
title: "Estimation of probability"
author: "Oksana Plastinina"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

```

## Модель пациента: оценка вероятности события полного исцеления после приема терапии

```{r }

# события: 1 - произошло полное исцеление, 2 - полного исцеления не произошло
event <- c('Пациент вылечился', 'Пациенту требуется дальнейшее лечение') 

# Зададим вероятности генеральной совакупности событиям 1 и 2 соответсвенно
Pr1 <- 0.75
Pr2 <- 0.25
Pr <- c(Pr1, Pr2)  

df <- data.frame(event, Pr)

```

## Однократная оценка по выборке

```{r sample_1}

# Задаем количество добровольцев 
n_patients <- 5 

# Генерируем одну выборку из наших событий из указанного числа добровольцев с учетом наших вероятностей
my_group_one_event <- sample (event, size = n_patients, replace = T, prob = Pr) 

print(my_group_one_event)

# Считаем вероятности наших событий исходя из данных эксперимента
p1 <- length(which(my_group_one_event == 'Пациент вылечился'))/(n_patients) 
p2 <- length(which(my_group_one_event == 'Пациенту требуется дальнейшее лечение'))/(n_patients)

print(c(p1, p2))

```

## Набираем статистику

```{r sample_n}

# Задаем количество добровольцев
n_patients <- 5

# Задаем количество повторений эксперимента
n_repeats <- 100

df_all_repeats <- data.frame(
  n_exp = rep(1:n_repeats, each = n_patients),
  ID =  rep(1:n_patients, n_repeats),
  cure = sample(event, size = n_patients*n_repeats, replace = T, prob = Pr)
)

```

## Оценка распределения веростностей в каждом эксперименте

```{r estimations}

theme_set(theme_bw())

#создаем датафрейм с вычисленными вероятностями каждого эксперимента
ndfg <- df_all_repeats %>% 
  group_by(n_exp) %>% 
  dplyr::summarise(p1 = (sum(cure == 'Пациент вылечился')/n_patients), p2 = (sum(cure == 'Пациенту требуется дальнейшее лечение')/n_patients) ) %>% 
  ungroup()

#генерируем графики распредления полученных вероятностей двух событий
ggplot(ndfg, aes(x = p1)) +
  geom_histogram(color = 'black', fill = 'seagreen', binwidth = 0.2) +
  labs(title = 'Распределение вероятности полного исцеления пациента',
       x = 'Вероятность полного исцеления пациента',
      y = 'Количество случаев')+
  theme(
    plot.title = element_text(hjust = 0.5)
  )

ggplot(ndfg, aes(x = p2)) +
  geom_histogram(color = 'black', fill = 'seagreen', binwidth = 0.2) +
  labs(title = 'Распределение вероятности необходимости продолжения лечения пациента',
       x = 'Вероятность необходимости продолжения лечения пациента',
      y = 'Количество случаев')+
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```

## Количественные и качественные итоги

```{r conclusions}

#Оцениваем среднии вероятности двух событий, полученных в эксперименте
mean(ndfg$p1)
mean(ndfg$p2)

#Оцениваем стандартную ошибку при оценке вероятности
errorp1 <- sqrt(mean((ndfg$p1-Pr1)^2))
errorp2 <- sqrt(mean((ndfg$p2-Pr2)^2))

print(errorp1)

```

Ошибку можно оценивать для вероятности одного из событий, т.к. она будет совпадать со второй.

При выборке из 5 пациентов - ошибка 0,18
При выборке из 125 (увеличили в 25 раз) - 0,04 (уменьшилась в 4,5 раз)
При выборке из 500 (увеличили в 100 раз) - 0,02 (уменьшилась в 9 раз)
При выборке 50000 (увеличили в 10000) - 0,002 (уменьшилась в 90 раз)

Таким образом, при анализе вероятности в зависимости от объема выборки представленным спопобом работает фундаментальное правило: при увеличение объема выборки в х раз, ошибка уменьшается в корень из х раз.