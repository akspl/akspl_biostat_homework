---
title: "Домашнее задание: Многомерный анализ данных"
subtitle: "Метаболический синдром - применение PCA и методов кластеризации"
author: "Потапенко Евгений, Пластинина Оксана"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: flatly
    highlight: tango
    code_folding: show
    number_sections: true
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
lang: ru
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.width = 8, fig.height = 6, fig.align = 'center')
```

```{r load-libraries, include=FALSE}
# Загрузка необходимых библиотек
if (!require("dplyr")) install.packages("dplyr"); library(dplyr)
if (!require("data.table")) install.packages("data.table"); library(data.table)
if (!require("tidyverse")) install.packages("tidyverse"); library(tidyverse)
if (!require("GGally")) install.packages("GGally"); library(GGally)
if (!require("umap")) install.packages("umap"); library(umap)
if (!require("factoextra")) install.packages("factoextra"); library(factoextra)
if (!require("pheatmap")) install.packages("pheatmap"); library(pheatmap)
if (!require("gridExtra")) install.packages("gridExtra"); library(gridExtra)

theme_set(theme_bw())
set.seed(42)
```

```{r echo = FALSE}
thememine <- theme(
  plot.title = element_text(size = 15, hjust = 0.5),
  axis.title = element_text(size = 12),
  axis.text = element_text(size = 9, colour = 'grey10'),
  panel.background = element_rect(fill = 'white'),
  panel.grid = element_line(colour = 'grey90')
)

theme_set(thememine)

labels_name <- c("Age" = 'Возраст',
                 "WaistCirc" = 'Окружность тела',
                 "BMI" = 'ИМТ',
                 "UrAlbCr" = 'Альбумин в моче',
                 "UricAcid" = 'Мочевая к-та в крови',
                 "BloodGlucose" = 'Глюкоза в крови',
                 "HDL" = 'Хотелстерин в крови',
                 "Triglycerides" = 'Триглицериды в крови')

labels_namediag <- c('0' = 'Нет синдрома', '1' = 'Есть синдром')
```

# Введение

## О датасете

В этом домашнем задании мы будем работать с датасетом **Metabolic Syndrome**, содержащим клинические и биохимические показатели пациентов. 

**Метаболический синдром** - это комплекс взаимосвязанных нарушений обмена веществ, включающий ожирение, инсулинорезистентность, дислипидемию и артериальную гипертензию. Этот синдром значительно повышает риск развития сердечно-сосудистых заболеваний и диабета 2 типа.

Датасет включает следующие показатели:

- **Антропометрические данные**: возраст, окружность талии, ИМТ
- **Метаболические показатели**: уровень глюкозы, триглицеридов, холестерина (HDL)
- **Биохимические маркеры**: альбумин в моче (UrAlbCr)
- **Социально-экономический статус**: уровень дохода (Его мы не будем использовать в анализе)

Цель работы - применить методы многомерного анализа (PCA) и кластеризации для выявления структуры данных и классификации пациентов по наличию метаболического синдрома.

## Задачи домашнего задания

1. Провести исследовательский анализ данных (EDA)
2. Выполнить предобработку и масштабирование данных
3. Применить методы снижения размерности (PCA, UMAP)
4. Определить оптимальное количество главных компонент
5. Интерпретировать результаты PCA
6. Применить методы кластеризации (иерархическая, K-means)
7. Сравнить качество кластеризации различными методами

# Загрузка и подготовка данных

## Загрузка датасета

Зарегистрируйтесь на платформе Kaggle и скачайте датасет:
[Metabolic Syndrome Dataset](https://www.kaggle.com/datasets/antimoni/metabolic-syndrome)

```{r load-data}
file <- 'data/Metabolic Syndrome.csv' # Обозначьте актуальный путь к файлу
# Загрузка данных
datama <- fread(file) %>% 
  select(-seqn, -Sex, -Marital, -Race, -Albuminuria, -Income)

# Удаление пропущенных значений
datama <- datama %>% na.omit()

# Сохранение целевой переменной
target <- datama$MetabolicSyndrome %>% as.factor() %>% recode('0' = 'Нет синдрома', '1' = 'Есть синдром')
datama$MetabolicSyndrome <- NULL

# Проверка размерности
cat("Размер датасета:", nrow(datama), "наблюдений,", ncol(datama), "переменных\n\n")
cat("Распределение классов:\n")
table(target)
```
1 - наличие метаболитного синдрома
0 - отсутсвие

# Исследовательский анализ данных (EDA)

## Визуализация взаимосвязей между переменными

Для комплексного анализа взаимосвязей между всеми переменными используем функцию `ggpairs()`, которая строит матрицу диаграмм рассеяния, гистограмм и коэффициентов корреляции.

```{r ggpairs-initial, fig.width=12, fig.height=12}

ggpairs(datama, 
        progress = F,
        columnLabels = labels_name,
        title = 'Матрица взаимосвязи переменных в исследовании метаболитного синдрома',
        lower = list(continuous = wrap("points", colour = 'cyan3', alpha =0.3 ) )
)+
  theme(
    plot.title = element_text(size = 18),
    axis.text.x = element_text(angle = 45)
  )
```

Подавляющее число переменных имеют статистически значимую, но слабую взаимосвязь (меньше 0,5).
Статистически значимая (на уровне р<0,001) взаимосвязь обнаружена между ИМТ и окружностью талии (коэф. корр. Пирсона = 0,9).
Статистически значимой взаимосвзи не обнаружено между ИМТ и уровнем альбумина в моче.

### Вопрос 1: Анализ распределений

**Вопрос:** Какие переменные имеют правостороннюю асимметрию (скошены вправо, имеют длинный хвост вправо)?

**Ответ:**  Правостороннюю ассиметрию имеют следующие пременные: уровень альбумина в моче, уровень глюкозы в крови, уровень триглециридов в крови, ИМТ, уровень холестерина. 

# Предобработка данных

## Логарифмирование переменных

Для переменных с сильной правосторонней асимметрией применяем логарифмическое преобразование, которое помогает:
- Нормализовать распределение
- Уменьшить влияние выбросов
- Стабилизировать дисперсию

Применяем `log1p()` (логарифм с добавлением 1), чтобы избежать проблем с нулевыми значениями:

```{r log-transform}
# Логарифмируем UrAlbCr (переменную с наиболее выраженной асимметрией)
datama$UrAlbCr <- datama$UrAlbCr %>% log1p()
```

## Масштабирование данных

Для корректной работы методов многомерного анализа необходимо стандартизировать данные (масштабирование к нулевому среднему и единичной дисперсии).

```{r scale-data}
data_scale <- scale(datama)
```

### Вопрос 2: Идентификация аутлайеров

**Вопрос:** Какие переменные имеют аутлайеры (выбросы > 3SD или < -3SD)? Отразите диапазон (range) каждой переменной в шкалированном датасете в виде таблицы/матрицы.

```{r outliers-table}
dataoutliers <- data_scale %>% 
  as.data.frame() %>% 
  select(where(function(x) any(x>3 | x < -3))) 

dataoutliers%>% 
  colnames()

dataoutliers %>%
  pivot_longer(everything(), names_to = 'Variable', values_to = 'range') %>% 
  group_by(Variable) %>% 
  summarise(
    Min = min(range) %>% round(2),
    Max = max(range)%>% round(2)
  ) 
```

**Ответ:** 
Переменные с аутлайерами и их диапазоны значений: окружность талии (-2.59;4.78), ИМТ (-2.33;6.09), уровень альбумина в моче (-0,17;19,49), уровень мочевой кислоты в крови (-2.57;4.07), уровень глюкозы в крови (-2.03; 8.08), уровень холестерина (-2.62; 6.44), уровень триглециридов в крови (-1.07; 15.12).

## Замена аутлайеров

Для уменьшения влияния экстремальных значений примените замену значений >3SD на 3 и <-3SD на -3:

```{r winsorize}
data_scale_out <- data_scale
data_scale_out[data_scale_out >  3] <-  3
data_scale_out[data_scale_out < -3] <- -3
```

## Визуализация обработанных данных

```{r ggpairs-scaled, fig.width=12, fig.height=12}

ggpairs(data_scale_out, 
        progress = F,
        columnLabels = labels_name,
        title = 'Матрица взаимосвязи страндартизированных переменных в исследовании метаболитного синдрома',
        lower = list(continuous = wrap("points", colour = 'cyan3', alpha =0.3 ) )) +
  theme(
    plot.title = element_text(size = 18)
  )
```

# Метод главных компонент (PCA)

## Применение PCA

Метод главных компонент (PCA) - это линейное преобразование данных в новую систему координат, где:
- Первая главная компонента объясняет максимальную долю вариации
- Каждая последующая компонента объясняет максимум оставшейся вариации
- Все компоненты ортогональны (некоррелированы) друг другу

```{r pca-application}
pca_result <- prcomp(data_scale_out, center = F, scale. = F)

pca_result
```


## Биплот: визуализация PCA

Биплот одновременно показывает:
- **Наблюдения** (пациенты) - точки, окрашенные по диагнозу
- **Переменные** - стрелки, указывающие направление максимального изменения

Постройте биплот используя fviz_pca_biplot(). Окрасьте точки по переменной target (диагноз)

```{r biplot-1, fig.width=8, fig.height=5}

pca_result_renam <- pca_result$var$coord

diagcol <- c('Нет синдрома' = 'mediumpurple',
               'Есть синдром' = 'lightgoldenrod')

fviz_pca_biplot(pca_result,
                geom = 'point',
                habillage = 'none',
                col.ind  = target,
                col.var = 'grey10',
                repel = TRUE,
                ggtheme = thememine
                )+
  scale_color_manual(
    values = diagcol
  )+
  scale_x_continuous(breaks = seq(-4,5,1))+
  scale_y_continuous(breaks = seq(-2,3,1))+
  labs(
    title = 'Биплот главных компонент',
    x = 'Главная компонента 1',
    y = 'Главная компонента 2',
    colour = 'Наличие метаболитного синдрома',
    shape = 'Наличие метаболитного синдрома'
  )

```

### Вопрос 3: Интерпретация биплота

**Вопрос 3.1:** Какие две переменные вносят наибольший вклад в PC2?

**Ответ:**  Наибольший вклад в PC2 вносят переменные Возраста и уровень альбумина, т.к. стрелки, обозначающие эти переменные имеют наибольшую длину проекции на вертикальную ось. Обе переменные положительно коррелируют с PC2.
 
 
**Вопрос 3.2:** Какие три переменные вносят наибольший вклад в PC1?

**Ответ:**  наибольший вклад в PC1 вносят переменные ИМТ, измерение окружности тела, и почти на равном уровне вносят вклад переменные уровня мочевой кислоты в крови (положительная корреляция) и уровень холестерина (отрицательная корреляция). Если интерпертировать также матрицу нагрузок видно, что влияние уровня холестерина выше влияние уровня мочевой кислоты.


**Вопрос 3.3:** Опишите, как в пространстве главных компонент разделяются наблюдения на основе диагноза. Какие 5 переменных вносят наибольший вклад в разделение пациентов с метаболическим синдромом и без него?

**Ответ:**  Переменные хорошо группируются по диагнозу вдоль горизонтальной оси, в обалсти положительных значений - пациенты с метаболическим синдромом, в области отрицательных - без. Наибольший вклад в PC1 и соответственно в разделение пациентов с метаболическим синдромом вносят следующие переменные: ИМТ, измерение окружности тела, уровень холестерина (отрицательная корреляция), уровень мочевой кислоты и уровень триглециридов в крови.



### Вопрос 4: Объясненная вариация

**Вопрос 4.1:** Сколько главных компонент необходимо для объяснения 90% вариации исходного датасета?

```{r cumsum}
# Ваш код здесь

summary(pca_result)
```

**Ответ:** Для объяснения не менее 90% вариаций исходного датасета необходиом 6 копомнент, которые объяснят 93,5% вариаций.

**Вопрос 4.2:** Какой процент вариации объясняют первые 3 главные компоненты? 

**Ответ:**  Первые три главные компоненты объяснят 67,4% вариаций.


# Выбор оптимального числа компонент

## Метод локтя (Scree Plot)

Метод локтя помогает определить, после какой компоненты добавление новых компонент дает незначительный прирост объясненной вариации.

```{r scree-plot, fig.width=10, fig.height=6}
# Ваш код здесь
fviz_eig(pca_result, 
         addlabels = TRUE,
         ncp = 8,
         main = "Scree plot: доля объясненной дисперсии",
         ggtheme = thememine)+
  labs(
    x = 'Главные компоненты',
    y = 'Доля объясненной дисперсии'
  )+
  scale_y_continuous(breaks = seq(0,40,5))+
  theme(
    plot.title = element_text(size = 18),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15)
  )
```

### Вопрос 5: Метод локтя

**Вопрос:** Используя метод локтя, определите оптимальное количество главных компонент. Какой процент вариации они объясняют?

**Ответ:** Оптимальное по методу локты количество главные компонент - 3, которые объясняют 64,7% вариации.


## Метод Кайзера

Метод Кайзера (Kaiser criterion) основан на собственных значениях (eigenvalues). 
```{r kaiser-method}

Kaiservalues = pca_result$sdev ^ 2
names(Kaiservalues) = paste0("PC", 1:length(Kaiservalues))

Kaiservalues %>% round(2)
```

### Вопрос 6: Метод Кайзера

**Вопрос:** Сколько главных компонент метод Кайзера рекомендует использовать для дальнейшего анализа?

**Ответ:** По методу Кайзера можно использовать 2 главные компоненты для дальнейшего анализа.


**Практические рекомендации:**

1. **Цель анализа имеет значение:**
   - Для **кластеризации** часто достаточно 3-4 компонент, объясняющих основные паттерны
   - Для **предсказательного моделирования** (например, линейной регрессии) может потребоваться больше компонент
   - Для **визуализации** обычно используют 2-3 компоненты

2. **Сложность данных:**
   - В нашем датасете относительно простая структура (~10 переменных)
   - В более сложных датасетах (>50 переменных) может потребоваться больше компонент

3. **Эмпирическая проверка:**
   - Оптимальное количество компонент можно проверить, оценивая качество последующей кластеризации
   - В данном задании мы проверим различные варианты

**Для нашего анализа:** Мы будем исследовать варианты с разным количеством компонент и выберем оптимальное на основе качества кластеризации.


# Интерпретация главных компонент

## Корреляции переменных с главными компонентами

Для понимания биологического смысла главных компонент необходимо проанализировать, какие исходные переменные вносят наибольший вклад в каждую компоненту.

Вычислите корреляции между исходными переменными и главными компонентами. Создайте тепловую карту используя pheatmap().

```{r var-correlation, fig.width=6, fig.height=3}

сorrlvar <- cor(data_scale_out, pca_result$x)

pheatmap(сorrlvar,
         cluster_rows = TRUE,
         cluster_cols = FALSE,
         display_numbers = TRUE,
         number_format = "%.2f",
         main = "Корреляция переменных с главными компонентами"
)
```

### Вопрос 7: Интерпретация компонент

**Вопрос:** Какие две переменные наиболее сильно коррелируют с каждой из первых трех главных компонент (PC1, PC2, PC3)?

**Ответ:** 
    
    PC1:
    - Переменная 1: [окружность тела] (корреляция: [0,90])
    - Переменная 2: [ИМТ] (корреляция: [0,83])
    
    PC2:
    - Переменная 1: [возраст] (корреляция: [0,82])
    - Переменная 2: [уровень альбумина в моче] (корреляция: [0,60])
    
    PC3:
    - Переменная 1: [уровень холестерина и уровень триглицеридов в крови] (корреляция: [-0,50 и 0,50 соответсвенно])
    - Переменная 2: [ИМТ] (корреляция: [-0,48])



# Кластеризация

## Иерархическая кластеризация


Примените иерархическую кластеризацию, постройте матрицу сопряженности и оцените совпадение предсказанных классов и диагноза с помощью Хи-квадрата.

```{r hierarchical-optimization}
####################### Параметры
numPCs <- 6
distMethod = 'euclidean'  # #'manhattan'
hclustMethod = 'ward.D2'     # 'average' # # #//'complete'
#######################


PCs = pca_result$x[,1:numPCs]


hclust_pc6 <-
    PCs %>%
    dist(method = distMethod) %>%
    hclust(method = hclustMethod)


hclusters_pc6_2 <- cutree(hclust_pc6, 2)

# Посчитаем матрицу сопряженности
contingency_table <- table(Кластер = hclusters_pc6_2, Диагноз = target)
contingency_table

chi2_test <- chisq.test(contingency_table)
print(chi2_test)
```

Для построения кластеризации использовали 6 главные компонент, объясняющих 93,5% вариаций, евклидово расстояние как мера расчета расстояний, т.к. наши данных находятся в одной размерности, и ward.D как метод иерархической кластеризации, инимизирующий внутрикластерную дисперсию.
при котором значения X-squared наивысшие среди трех остальных.

Согласно полученному критерию Хи-квадрат для проверки независимости, разделение на кластеры и поставленный диагноз имеют статистически значимую взаимосвязь по уровню значимости 0.05 (p < 2.2e-16, X-квадрат = 469.93).

При этом, кластер 1 на 87,5% состоит из пациентов, не имеющих метаболического синдрома, а кластер 2 на 70,0% из пациентов, имеющих метаболический синдром.

### Подбор оптимальных параметров

Протестируйте различные комбинации и выберите ту которая даёт лучшую кластеризацию на основне Хи-квадрата:
  - Количество главных компонент: 1-6 (**numPCs**)
  - Метрики расстояния: euclidean, manhattan (**distMethod**)
  - Методы связывания: ward.D2, complete, average (**hclustMethod**)

Статистика теста Хи-квадрата наибольшая при использовании одной компоненты. Остальные компоненты возможно вносят излишную информацию, не так связаную с постановлением диагноза.
Изменение меры расчета расстояния не влияет на получаемую статистику. Оба метода равноэффективны, т.к. наши данные находся в одной размерности и не имеют аутлайнеров.
ward.D как метод иерархической кластеризации дает наибольшие значения X-squared среди трех остальных методов.

### Визуализация иерархической кластеризации

Создайте тепловую карту с иерархической кластеризацией. Используйте оптимальные параметры. Добавьте аннотацию с диагнозами. 

Тепловая карта с использованием всех главных компонент. Кластер с большинством пациентов с синдромом также имеет много наблюдений пациентов без синдрома.

```{r heatmap-hierarchical1, fig.width=5, fig.height=5, fig.align='center'}
# Создание фрейма данных с аннотациями
annotation_row <- 
  data.frame(
    'Диагноз' = target)

row.names(data_scale_out) <- paste0('obs', 1:nrow(data_scale_out))
row.names(annotation_row) <- row.names(data_scale_out)

# Тепловая карта с аннотациями кластеров
pheatmap(data_scale_out,
         
         # Кластеризация
         cluster_cols = F,
         cluster_rows = T,
      
         clustering_method = 'ward.D2',
         clustering_distance_rows = 'euclidean',
         cutree_rows = 2,
         
         # Внешний вид
         show_rownames = F, # Убираем подписывание колонок (индексы строк/наблюдений),
         angle_col = 45, # Подписи под углом
        
         # Аннотации
         annotation_row = annotation_row,
         annotation_colors = list('Диагноз' = c('Нет синдрома' = "mediumpurple",
                                          'Есть синдром' = "lightgoldenrod"))
         )
```

При построении тепловой карты с использованием одной компоненты, как оптимальным количеством (по результатам Хи-квадрат), визуально лучше разделяет пациентов. 
В кластере с преимущественным расположением пациентов без синдрома располагается больше наблюдений пациентов с синдромом, но второй кластер по сравнению с первым гарфиком преимущественно состоит из пациентов с синдромом.

```{r heatmap-hierarchical2, fig.width=4, fig.height=5}


# Создание фрейма данных с аннотациями
annotation_row <- 
  data.frame(
    'Диагноз' = target)


row.names(data_scale_out) <- paste0('obs', 1:nrow(data_scale_out))
row.names(annotation_row) <- row.names(data_scale_out)

pca1mart <- data.frame(PC1 = pca_result$x[,1])
rownames(pca1mart) <- paste0('obs', 1:nrow(data_scale_out))
pca1mart  <-  as.matrix(pca1mart)

# Тепловая карта с аннотациями кластеров
pheatmap(pca1mart,
         
         # Кластеризация
         cluster_cols = F,
         cluster_rows = T,
      
         clustering_method = 'ward.D2',
         clustering_distance_rows = 'euclidean',
         cutree_rows = 2,
         
         # Внешний вид
         show_rownames = F, # Убираем подписывание колонок (индексы строк/наблюдений),
         angle_col = 45, # Подписи под углом
        
         # Аннотации
         annotation_row = annotation_row,
         annotation_colors = list('Диагноз' = c('Нет синдрома' = "mediumpurple",
                                          'Есть синдром' = "lightgoldenrod"))
         )
```

## K-means кластеризация

Теперь сравним результаты с методом K-means, который использует другой подход к кластеризации.

Протестируйте K-means с разным количеством главных компонент (1-6).


```{r kmeans-optimization}
# Ваш код здесь

PCs = pca_result$x[,1:2]
kmeans_pc6_2 = kmeans(PCs, centers = 2, nstart = 25)


contingency_table <- table(Кластер = kmeans_pc6_2$cluster, Диагноз = target)
contingency_table

chi2_test <- chisq.test(contingency_table)
print(chi2_test)
```

## Вопрос 8: Оптимизация K-Means

**Вопрос:** Какое минимальное количество PCs даёт наилучшую кластеризацию основываясь на Хи-квадрат?

**Ответ:** 2 главные компоненты дают наибольшую статистику Хи-квадрат.


## Вопрос 9: Сравнение методов кластеризации

**Вопрос:** На основе статистики χ² (Chi-squared), какой метод и с каким количеством главных компонент дает наилучший результат классификации?


**Ответ:**  Метод методом K-means с двумя главными компонетами дает значения Хи-квадрат несколько выше значений, полученных с помощью иерархической кластеризацией с использованием 1 компоненты.


# Визуализация лучшей кластеризации

Постройте два биплота fviz_pca_biplot() рядом:  
1) С окраской по реальному диагнозу  
2) С окраской по кластерам лучшего метода  
Используйте gridExtra::grid.arrange(..., ncol = 2) для размещения графиков  

```{r diagnosis-comparison, fig.width=14, fig.height=6}
# Ваш код здесь

plottarg <- fviz_pca_biplot(pca_result,
                geom = 'point',
                habillage = 'none',
                col.ind  = target,
                col.var = 'grey10',
                repel = TRUE,
                ggtheme = thememine
                )+
  scale_color_manual(
    values = diagcol
  )+
  scale_x_continuous(breaks = seq(-4,5,1))+
  scale_y_continuous(breaks = seq(-2,3,1))+
  labs(
    title = 'Биплот главных компонент',
    x = 'Главная компонента 1',
    y = 'Главная компонента 2',
    colour = 'Наличие метаболитного синдрома',
    shape = 'Наличие метаболитного синдрома'
  )+
  theme(
    legend.position = 'bottom',
    legend.justification = 'centre'
  )



plotclus <- fviz_pca_biplot(pca_result,
                geom = 'point',
                habillage = 'none',
                col.ind  = factor(kmeans_pc6_2$cluster),
                col.var = 'grey10',
                repel = TRUE,
                ggtheme = thememine
                )+
  scale_x_continuous(breaks = seq(-4,5,1))+
  scale_y_continuous(breaks = seq(-2,3,1))+
  scale_colour_manual(
    values = c('1' = 'plum1',
               '2' = 'bisque3')
  )+
  labs(
    title = 'Биплот главных компонент',
    x = 'Главная компонента 1',
    y = 'Главная компонента 2',
    colour = 'Кластер',
    shape = 'Кластер'
  )+
  theme(
    legend.position = 'bottom',
    legend.justification = 'centre'
  )+
  theme(
    legend.position = 'bottom',
    legend.justification = 'centre'
  )

gridExtra::grid.arrange(plottarg, plotclus, ncol = 2)


```

На этом заканчивается основная часть задания! Выполнив её, вы сможете получить 100 баллов!

# Дополнительное задание: Попробуйте построить UMAP на исходном датасете

```{r fig.height=5, fig.width= 8}
# Настройки UMAP
umap_config <- umap.defaults
umap_config$n_neighbors <- 50
umap_config$min_dist <- 0.01
umap_config$metric <- 'euclidean'
umap_config$random_state <- 42

# Применяем UMAP
umap_result <- umap(data_scale_out, config = umap_config)

# Визуализация
umap_data <- data.frame(
  UMAP1 = umap_result$layout[, 1],
  UMAP2 = umap_result$layout[, 2],
  Diagnosis = target
)

ggplot(umap_data, aes(x = UMAP1, y = UMAP2, color = Diagnosis)) +
  geom_point(alpha = 0.6, size = 2) +
  scale_color_manual(
    name = 'Наличие метаболитного синдрома',
    values = diagcol) +
  scale_x_continuous(breaks = seq(-4,4,1))+
  scale_y_continuous(breaks = seq(-3,3,1))+
  labs(title = "UMAP визуализация",
       x = "UMAP 1",
       y = "UMAP 2") +
  theme() +
  theme(legend.position = "right")
```

Из графика видно, что группы частично разделяются, пациенты с синдромом сконцентрированы в верхней части графика (UMAP2>1), без синдрома (UMAP2<-1) - в нижней. Однко из-за схожести групп кластеризация не идеальная и группы перемешиваются между собой преимущесвенно в центре графика и частично у полюсов второго кластера.

![Well done](https://media.makeameme.org/created/well-done-82c060d015.jpg)
